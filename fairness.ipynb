{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação de Fairness no modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a avaliação de fairness, será utilizada a métrica Equal opportunity, e será realizada a análise na classe \"sexo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos calcular a métrica de fairness para a classe sexo, analisar, e utilizar técnicas de mitigação de viés a fim de comparar os resultados com o modelo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Quantidade ovos encontrados', 'Escolaridade', 'Sexo', 'Resultado',\n",
      "       'Exame_Nao_Realizado', 'Exame_Negativo', 'Exame_Positivo',\n",
      "       'Tratamento_Nao', 'Tratamento_Sim_Oxaminiquine',\n",
      "       'Tratamento_Sim_Praziquantel', 'Forma_Aguda', 'Forma_Hepato_Esplenica',\n",
      "       'Forma_Hepato_Intestinal', 'Forma_Intestinal', 'Forma_Outra', 'Idade',\n",
      "       'Regiao_Centro-Oeste', 'Regiao_Nordeste', 'Regiao_Norte',\n",
      "       'Regiao_Sudeste', 'Regiao_Sul'],\n",
      "      dtype='object')\n",
      "(1441, 21)\n"
     ]
    }
   ],
   "source": [
    "# Carregando os dados de teste\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv('./source/datasets/df_teste.csv')\n",
    "train_data = pd.read_csv('./source/datasets/df_treino.csv')\n",
    "print(test_data.columns)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas que não agregam na avaliação (Assim como realizado no treinamento)\n",
    "# test_data = test_data.drop(columns=['Exame_Desconhecido', 'Tratamento_Ignorado', 'Forma_Nao_especificado', 'Regiao_Nao_especificado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    740\n",
      "1    701\n",
      "Name: Escolaridade, dtype: int64\n",
      "1    3162\n",
      "0    2622\n",
      "Name: Escolaridade, dtype: int64\n",
      "Alfabetizados Teste:  0    695\n",
      "1      6\n",
      "Name: Resultado, dtype: int64\n",
      "Analfabetos Teste:  0    714\n",
      "1     26\n",
      "Name: Resultado, dtype: int64\n",
      "Alfabetizados Treino:  0    3124\n",
      "1      38\n",
      "Name: Resultado, dtype: int64\n",
      "Analfabetos treino:  0    2502\n",
      "1     120\n",
      "Name: Resultado, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_data['Escolaridade'].value_counts())\n",
    "print(train_data['Escolaridade'].value_counts())\n",
    "\n",
    "print(\"Alfabetizados Teste: \", test_data[test_data['Escolaridade'] == 1]['Resultado'].value_counts())\n",
    "print(\"Analfabetos Teste: \", test_data[test_data['Escolaridade'] == 0]['Resultado'].value_counts())\n",
    "\n",
    "print(\"Alfabetizados Treino: \", train_data[train_data['Escolaridade'] == 1]['Resultado'].value_counts())\n",
    "print(\"Analfabetos treino: \", train_data[train_data['Escolaridade'] == 0]['Resultado'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mortes absolutas por sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Masculino  Feminino\n",
      "Treino         81        77\n",
      "Teste          17        15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = train_data\n",
    "df_test = test_data\n",
    "# Count male deaths (Resultado==1) in the training set (Sexo==1)\n",
    "male_deaths_train = df_train[df_train['Sexo'] == 1]['Resultado'].value_counts().get(1, 0)\n",
    "# Count female deaths (Resultado==1) in the training set (Sexo==0)\n",
    "female_deaths_train = df_train[df_train['Sexo'] == 0]['Resultado'].value_counts().get(1, 0)\n",
    "\n",
    "# Count male deaths (Resultado==1) in the test set (Sexo==1)\n",
    "male_deaths_test = df_test[df_test['Sexo'] == 1]['Resultado'].value_counts().get(1, 0)\n",
    "# Count female deaths (Resultado==1) in the test set (Sexo==0)\n",
    "female_deaths_test = df_test[df_test['Sexo'] == 0]['Resultado'].value_counts().get(1, 0)\n",
    "\n",
    "# Create a summary DataFrame with rows for train and test and columns for each sex\n",
    "data = {\n",
    "    \"Masculino\": [male_deaths_train, male_deaths_test],\n",
    "    \"Feminino\": [female_deaths_train, female_deaths_test]\n",
    "}\n",
    "df_summary = pd.DataFrame(data, index=[\"Treino\", \"Teste\"])\n",
    "\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Alfabetizado  Não-Alfabetizado\n",
      "Treino            38               120\n",
      "Teste              6                26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = train_data\n",
    "df_test = test_data\n",
    "# Count male deaths (Resultado==1) in the training set (Sexo==1)\n",
    "male_deaths_train = df_train[df_train['Escolaridade'] == 1]['Resultado'].value_counts().get(1, 0)\n",
    "# Count female deaths (Resultado==1) in the training set (Escolaridade==0)\n",
    "female_deaths_train = df_train[df_train['Escolaridade'] == 0]['Resultado'].value_counts().get(1, 0)\n",
    "\n",
    "# Count male deaths (Resultado==1) in the test set (Escolaridade==1)\n",
    "male_deaths_test = df_test[df_test['Escolaridade'] == 1]['Resultado'].value_counts().get(1, 0)\n",
    "# Count female deaths (Resultado==1) in the test set (Escolaridade==0)\n",
    "female_deaths_test = df_test[df_test['Escolaridade'] == 0]['Resultado'].value_counts().get(1, 0)\n",
    "\n",
    "# Create a summary DataFrame with rows for train and test and columns for each sex\n",
    "data = {\n",
    "    \"Alfabetizado\": [male_deaths_train, male_deaths_test],\n",
    "    \"Não-Alfabetizado\": [female_deaths_train, female_deaths_test]\n",
    "}\n",
    "df_summary = pd.DataFrame(data, index=[\"Treino\", \"Teste\"])\n",
    "\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taxa de mortalidade por sexo em cada conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feminino</th>\n",
       "      <th>Masculino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Treino</th>\n",
       "      <td>3,52%</td>\n",
       "      <td>2,21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teste</th>\n",
       "      <td>2,97%</td>\n",
       "      <td>1,73%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feminino Masculino\n",
       "Treino    3,52%     2,21%\n",
       "Teste     2,97%     1,73%"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate death rates for the training data (as fractions) using normalize=True:\n",
    "male_death_rate_train = df_train[df_train['Sexo'] == 1]['Resultado'].mean()\n",
    "female_death_rate_train = df_train[df_train['Sexo'] == 0]['Resultado'].mean()\n",
    "\n",
    "# Calculate death rates for the test data (as fractions)\n",
    "male_death_rate_test = df_test[df_test['Sexo'] == 1]['Resultado'].mean()\n",
    "female_death_rate_test = df_test[df_test['Sexo'] == 0]['Resultado'].mean()\n",
    "\n",
    "# Convert the rates to readable percentages with two decimals and a comma as decimal separator\n",
    "male_death_rate_train_str = f\"{male_death_rate_train * 100:.2f}%\".replace('.', ',')\n",
    "female_death_rate_train_str = f\"{female_death_rate_train * 100:.2f}%\".replace('.', ',')\n",
    "male_death_rate_test_str = f\"{male_death_rate_test * 100:.2f}%\".replace('.', ',')\n",
    "female_death_rate_test_str = f\"{female_death_rate_test * 100:.2f}%\".replace('.', ',')\n",
    "\n",
    "# Create a summary DataFrame with the percentages as strings\n",
    "data = {\n",
    "    \"Feminino\": [male_death_rate_train_str, male_death_rate_test_str],\n",
    "    \"Masculino\": [female_death_rate_train_str, female_death_rate_test_str]\n",
    "}\n",
    "\n",
    "df_summary_rates = pd.DataFrame(data, index=[\"Treino\", \"Teste\"])\n",
    "df_summary_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alfabetizado</th>\n",
       "      <th>Não Alfabetizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Treino</th>\n",
       "      <td>1,20%</td>\n",
       "      <td>4,58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teste</th>\n",
       "      <td>0,86%</td>\n",
       "      <td>3,51%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Alfabetizado Não Alfabetizado\n",
       "Treino        1,20%            4,58%\n",
       "Teste         0,86%            3,51%"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate death rates for the training data (as fractions) using normalize=True:\n",
    "alfa_death_rate_train = df_train[df_train['Escolaridade'] == 1]['Resultado'].value_counts(normalize=True).get(1, 0)\n",
    "nao_alfa__death_rate_train = df_train[df_train['Escolaridade'] == 0]['Resultado'].value_counts(normalize=True).get(1, 0)\n",
    "\n",
    "# Calculate death rates for the test data (as fractions)\n",
    "alfa_death_rate_test = df_test[df_test['Escolaridade'] == 1]['Resultado'].value_counts(normalize=True).get(1, 0)\n",
    "nao_alfa__death_rate_test = df_test[df_test['Escolaridade'] == 0]['Resultado'].value_counts(normalize=True).get(1, 0)\n",
    "\n",
    "# Convert the rates to readable percentages with two decimals and a comma as decimal separator\n",
    "alfa_death_rate_train_str = f\"{alfa_death_rate_train * 100:.2f}%\".replace('.', ',')\n",
    "nao_alfa_death_rate_train_str = f\"{nao_alfa__death_rate_train * 100:.2f}%\".replace('.', ',')\n",
    "alfa_death_rate_test_str = f\"{alfa_death_rate_test * 100:.2f}%\".replace('.', ',')\n",
    "nao_alfa_death_rate_test_str = f\"{nao_alfa__death_rate_test * 100:.2f}%\".replace('.', ',')\n",
    "\n",
    "# Create a summary DataFrame with the percentages as strings\n",
    "data = {\n",
    "    \"Alfabetizado\": [alfa_death_rate_train_str, alfa_death_rate_test_str],\n",
    "    \"Não Alfabetizado\": [nao_alfa_death_rate_train_str, nao_alfa_death_rate_test_str]\n",
    "}\n",
    "\n",
    "df_summary_rates = pd.DataFrame(data, index=[\"Treino\", \"Teste\"])\n",
    "df_summary_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os conjuntos de predições e target\n",
    "X_test = test_data.drop(columns=['Resultado'])\n",
    "y_test = test_data['Resultado']\n",
    "sexo = test_data['Sexo']\n",
    "escolaridade = test_data['Escolaridade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "import pickle\n",
    "with open('source/models/best_model.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando as predições no conjunto de teste para o melhor modelo encontrado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Quantidade ovos encontrados', 'Escolaridade', 'Sexo',\n",
       "       'Exame_Nao_Realizado', 'Exame_Negativo', 'Exame_Positivo',\n",
       "       'Tratamento_Nao', 'Tratamento_Sim_Oxaminiquine',\n",
       "       'Tratamento_Sim_Praziquantel', 'Forma_Aguda', 'Forma_Hepato_Esplenica',\n",
       "       'Forma_Hepato_Intestinal', 'Forma_Intestinal', 'Forma_Outra', 'Idade',\n",
       "       'Regiao_Centro-Oeste', 'Regiao_Nordeste', 'Regiao_Norte',\n",
       "       'Regiao_Sudeste', 'Regiao_Sul'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando para sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lipecorradini/.local/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(sexo.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nosso caso, o valor 0 é masculino e 0 é feminino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall para o grupo Feminino: 0.6471\n",
      "Recall para o grupo Masculino: 0.8667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "grupos = sexo.unique()\n",
    "labels = ['Masculino', 'Feminino']\n",
    "for value in grupos:\n",
    "    idx_gp = sexo == value # Escolhe o sexo definido e calcula o recall\n",
    "    recall = recall_score(y_test[idx_gp], y_pred[idx_gp])\n",
    "    print(f'Recall para o grupo {labels[value]}: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando para escolaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando para escolaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall para o grupo Analfabeto: 0.7000\n",
      "Recall para o grupo 1ª a 4ª série incompleta: 1.0000\n",
      "Recall para o grupo 4ª série completa: 1.0000\n",
      "Recall para o grupo 5ª a 8ª série incompleta: 0.0000\n",
      "Recall para o grupo Ensino fundamental completo: 0.5000\n",
      "Recall para o grupo Ensino médio incompleto: 1.0000\n",
      "Recall para o grupo Ensino médio completo: 0.0000\n",
      "Recall para o grupo Educação superior incompleta: 0.0000\n",
      "Recall para o grupo Educação superior completa: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lipecorradini/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/lipecorradini/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/lipecorradini/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "escolaridade_labels = {\n",
    "    0: \"Analfabeto\",\n",
    "    1: \"1ª a 4ª série incompleta\",\n",
    "    2: \"4ª série completa\",\n",
    "    3: \"5ª a 8ª série incompleta\",\n",
    "    4: \"Ensino fundamental completo\",\n",
    "    5: \"Ensino médio incompleto\",\n",
    "    6: \"Ensino médio completo\",\n",
    "    7: \"Educação superior incompleta\",\n",
    "    8: \"Educação superior completa\",\n",
    "}\n",
    "\n",
    "for value in escolaridade_labels.keys():\n",
    "    idx_gp = escolaridade == value # Escolhe a escolaridade definida e calcula o recall\n",
    "    recall = recall_score(y_test[idx_gp], y_pred[idx_gp])\n",
    "    print(f'Recall para o grupo {escolaridade_labels[value]}: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos avaliar a métrica em relação a uma avaliação binária da escolaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nova_Escolaridade(x):\n",
    "    if x < 2:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "escolaridade_bin = escolaridade.apply(lambda x: nova_Escolaridade(x))  # Agrupando em ensino superior completo ou não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    619\n",
      "6    212\n",
      "3    135\n",
      "1    121\n",
      "2    104\n",
      "5    101\n",
      "4     83\n",
      "8     48\n",
      "7     18\n",
      "Name: Escolaridade, dtype: int64\n",
      "0    740\n",
      "1    701\n",
      "Name: Escolaridade, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(escolaridade.value_counts())\n",
    "print(escolaridade_bin.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall para o grupo Não alfabetizado: 0.7692\n",
      "Mortes para o grupo Não alfabetizado: 26\n",
      "---------------------------------------------------------------\n",
      "Recall para o grupo Alfabetizado: 0.6667\n",
      "Mortes para o grupo Alfabetizado: 6\n",
      "---------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16801/995386746.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(f\"Mortes para o grupo {escolaridade_bin_labels[value]}: {test_data[y_test == 1][idx_gp].shape[0]}\")\n",
      "/tmp/ipykernel_16801/995386746.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(f\"Mortes para o grupo {escolaridade_bin_labels[value]}: {test_data[y_test == 1][idx_gp].shape[0]}\")\n"
     ]
    }
   ],
   "source": [
    "escolaridade_bin_labels = {\n",
    "    0: \"Não alfabetizado\",\n",
    "    1: \"Alfabetizado\",\n",
    "}\n",
    "\n",
    "for value in escolaridade_bin_labels.keys():\n",
    "    idx_gp = escolaridade_bin == value # Escolhe a escolaridade definida e calcula o recall\n",
    "    recall = recall_score(y_test[idx_gp], y_pred[idx_gp])\n",
    "    print(f'Recall para o grupo {escolaridade_bin_labels[value]}: {recall:.4f}')\n",
    "    print(f\"Mortes para o grupo {escolaridade_bin_labels[value]}: {test_data[y_test == 1][idx_gp].shape[0]}\")\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Não alfabetizado</th>\n",
       "      <th>Alfabetizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Não alfabetizado  Alfabetizado\n",
       "0          0.769231      0.666667"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Initialize an empty dictionary to store the recall for each escolaridade group\n",
    "recall_dict = {}\n",
    "\n",
    "for value, label in escolaridade_bin_labels.items():\n",
    "    # Create a boolean mask for the given escolaridade value \n",
    "    idx_gp = escolaridade_bin == value\n",
    "    # Calculate recall for that group using the values from y_test and y_pred\n",
    "    recall_val = recall_score(y_test[idx_gp], y_pred[idx_gp])\n",
    "    # Save the recall in the dictionary with the descriptive label as key\n",
    "    recall_dict[label] = recall_val\n",
    "    \n",
    "# Transform the recall_dict into a DataFrame with a single row\n",
    "df_recall = pd.DataFrame([recall_dict])\n",
    "\n",
    "df_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talvez chegue no final e perceba que nao faz sentido usar essa métrica de fairness, porque estamos tentando ajustar baseado no que já tínhamos antes (não entendi muito bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./source/datasets/df_treino.csv')\n",
    "test_data = pd.read_csv('./source/datasets/df_teste.csv')\n",
    "\n",
    "# Ajustado os conjuntos para preduções binárias da escolaridade\n",
    "train_data['Escolaridade'] = train_data['Escolaridade'].apply(lambda x: nova_Escolaridade(x))\n",
    "test_data['Escolaridade'] = test_data['Escolaridade'].apply(lambda x: nova_Escolaridade(x))\n",
    "\n",
    "# Salvando os conjuntos ajustados\n",
    "train_data.to_csv('entrega-1/df_treino_fairness.csv', index=False)\n",
    "test_data.to_csv('entrega-1/df_teste_fairness.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando o resultado com o modelo treinado balanceando os dados da classe sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "import pickle\n",
    "with open('source/models/best_model_fairness_sexo.pkl', 'rb') as file:\n",
    "    best_model_fairness = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall para o grupo Masculino: 0.7333\n",
      "Recall para o grupo Feminino: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lipecorradini/.local/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_pred_f = best_model_fairness.predict(X_test)\n",
    "\n",
    "sexo_bin_labels = {\n",
    "    0: \"Masculino\",\n",
    "    1: \"Feminino\",\n",
    "}\n",
    "\n",
    "for value in sexo_bin_labels.keys():\n",
    "    idx_gp = sexo == value # Escolhe a sexo definida e calcula o recall\n",
    "    recall = recall_score(y_test[idx_gp], y_pred_f[idx_gp])\n",
    "    print(f'Recall para o grupo {sexo_bin_labels[value]}: {recall:.4f}')\n",
    "    # print(f\"Mortes para o grupo {sexo_bin_labels[value]}: {test_data[y_test == 1][idx_gp].shape[0]}\")\n",
    "    # print(\"---------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
