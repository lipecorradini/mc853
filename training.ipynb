{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('./source/datasets/df_treino.csv')\n",
    "df_test = pd.read_csv('./source/datasets/df_teste.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5626\n",
      "1     158\n",
      "Name: Resultado, dtype: int64\n",
      "0    1409\n",
      "1      32\n",
      "Name: Resultado, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Resultado'].value_counts())\n",
    "print(df_test['Resultado'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['Resultado'].to_numpy()\n",
    "X_train = df_train.drop(['Resultado'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_save = y_train\n",
    "X_train_save = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Balanceando as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, precisamos garantir representatividade de ao menos 1,5x da classe majoritária sobre a minoritária. Como temos consideravelmente mais instâncias de pessoas que não faleceram, vamos buscar utilizar diferentes técnicas tanto para selecionar instâncias da classe majoritária quanto para aumentar as instâncias da classe majoritária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, iremos utilizar a biblioteca imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, aumentar a instância da classe minoritaria até atingir 20% da majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade da classe minoritária antes da aumentação:  (array([0, 1]), array([5626,  158]))\n",
      "Quantidade da classe minoritária após aumentação:  (array([0, 1]), array([5626, 1125]))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "oversample = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "print(\"Quantidade da classe minoritária antes da aumentação: \", np.unique(y_train, return_counts=True))\n",
    "\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print(\"Quantidade da classe minoritária após aumentação: \", np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar undersampling para reduzir a classe majoritária. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2812, 20)\n",
      "(2812,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "nm = NearMiss(sampling_strategy={0:1687,1:1125})\n",
    "X_train, y_train = nm.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1687, 1125]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise anterior foi usada apenas para demonstrar como devem ser balanceados os modelos. O balanceamento será realizado dentro dos folds de treinamento para cada iteração do k-fold, a fim de que a valicação reflita melhor os padrões que serão vistos nos conjuntos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([5626,  158]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train = X_train_save\n",
    "y_train = y_train_save\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grids = {\n",
    "    'kNN': {\n",
    "        'n_neighbors': [1, 5, 10],\n",
    "        'p': [1, 2],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'class_weight': ['balanced', {0: 1, 1: 1}]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [10, 100, 200],\n",
    "        'max_depth': [10, 50],\n",
    "        'min_samples_split': [2, 10, 30]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos os parâmetros iniciais, instanciando os modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos base\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "models = [('kNN', knn), ('Logistic Regression', lr), ('Random Forest', rf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO: kNN\n",
      "Fold 1\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  1\n",
      "Fold 2\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  2\n",
      "Fold 3\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  3\n",
      "Fold 4\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  4\n",
      "Fold 5\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  5\n",
      "MODELO: Logistic Regression\n",
      "Fold 1\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  1\n",
      "Fold 2\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  2\n",
      "Fold 3\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  3\n",
      "Fold 4\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  4\n",
      "Fold 5\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  5\n",
      "MODELO: Random Forest\n",
      "Fold 1\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  1\n",
      "Fold 2\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  2\n",
      "Fold 3\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  3\n",
      "Fold 4\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  4\n",
      "Fold 5\n",
      "Distribuição y treino:  (array([0, 1]), array([1500,  900]))\n",
      "Added report!  5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_reports = {}\n",
    "for name, base_model in models:\n",
    "\n",
    "    print(f\"MODELO: {name}\")\n",
    "    all_reports[name] = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        print(f'Fold {fold+1}')\n",
    "        X_train_fold, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Transformando classe minoritária em 20% da classe majoritária\n",
    "        oversample = SMOTE(sampling_strategy=0.2, random_state=42)\n",
    "        X_train_fold, y_train_fold = oversample.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Transformando classe majoritária em 1.5x da minoritária\n",
    "        nm = NearMiss(sampling_strategy=0.6)\n",
    "        X_train_fold, y_train_fold = nm.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Mostrando a distribuição do y treino, para ver se o 60% foi respeitado\n",
    "        print(\"Distribuição y treino: \", np.unique(y_train_fold, return_counts=True))\n",
    "\n",
    "        # Clonando o modelo\n",
    "        model = clone(base_model)\n",
    "\n",
    "        # Definindo o GridSearch\n",
    "        grid = GridSearchCV(\n",
    "            model,\n",
    "            param_grid=param_grids[name],\n",
    "            scoring={'recall': 'recall', 'precision': 'precision'},\n",
    "            refit='recall',  # Use 'recall' to refit the model\n",
    "            cv=5,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        # Ajustando o modelo com os dados balanceados\n",
    "        grid.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Usando o melhor modelo\n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "        # Avaliando o modelo\n",
    "        y_pred = best_model.predict(X_val)\n",
    "\n",
    "        # Gerando o classification report\n",
    "        report = classification_report(y_val, y_pred, output_dict=True)\n",
    "        all_reports[name].append(report)  \n",
    "        print(\"Added report! \", len(all_reports[name]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(all_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"KNN: {len(all_reports['kNN'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro AVG para cada modelo:\n",
      "KNN: {'precision': 0.5939780953027936, 'recall': 0.8570035842293906, 'f1-score': 0.6306923791821561, 'support': 1156.0}\n",
      "Logistic Regression: {'precision': 0.6379084967320261, 'recall': 0.8599856630824373, 'f1-score': 0.6914138559135733, 'support': 1156.0}\n",
      "Random Forest: {'precision': 0.6551536806034393, 'recall': 0.7129175627240143, 'f1-score': 0.6789121561239524, 'support': 1156.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro AVG para cada modelo:\")\n",
    "print(f\"KNN: {all_reports['kNN'][-1]['macro avg']}\")\n",
    "print(f\"Logistic Regression: {all_reports['Logistic Regression'][-1]['macro avg']}\")\n",
    "print(f\"Random Forest: {all_reports['Random Forest'][-1]['macro avg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da classe minoritária para cada modelo:\n",
      "KNN: {'precision': 0.2682926829268293, 'recall': 0.3548387096774194, 'f1-score': 0.3055555555555556, 'support': 31.0}\n",
      "Logistic Regression: {'precision': 0.18181818181818182, 'recall': 0.1875, 'f1-score': 0.18461538461538463, 'support': 32.0}\n",
      "Random Forest: {'precision': 0.3114754098360656, 'recall': 0.59375, 'f1-score': 0.40860215053763443, 'support': 32.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Métricas da classe minoritária para cada modelo:\")\n",
    "print(f\"KNN: {all_reports[0]['1']}\")\n",
    "print(f\"Logistic Regression: {all_reports[1]['1']}\")\n",
    "print(f\"Random Forest: {all_reports[2]['1']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
